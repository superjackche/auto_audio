#!/usr/bin/env python3
"""
æœ€ç»ˆç®€åŒ–æµ‹è¯•è„šæœ¬ - ä½¿ç”¨ç‹¬ç«‹æ¨¡å—
é€‚ç”¨äºPython 3.13.2
"""

import sys
import os

def main():
    print("=" * 60)
    print("Auto Audio ç³»ç»Ÿ - Python 3.13.2 å…¼å®¹ç‰ˆæœ¬")
    print("=" * 60)
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    
    # æ·»åŠ è·¯å¾„
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
    
    print("\\n1. æµ‹è¯•ç‹¬ç«‹æ–‡æœ¬åˆ†æå™¨...")
    try:
        from nlp.analyzer_independent import IndependentTextAnalyzer
        
        analyzer = IndependentTextAnalyzer()
        info = analyzer.get_analyzer_info()
        print(f"   âœ“ åˆ†æå™¨ç±»å‹: {info['tokenizer_type']}")
        print(f"   âœ“ çŠ¶æ€: {'å¯ç”¨' if info['available'] else 'ä¸å¯ç”¨'}")
        
        # æµ‹è¯•åˆ†æåŠŸèƒ½
        test_cases = [
            "è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯ä¸­æ–‡åˆ†æåŠŸèƒ½ã€‚",
            "This is an excellent test text for English analysis.",
            "è¿™æ˜¯ä¸€ä¸ªä¸­è‹±æ–‡æ··åˆçš„æ–‡æœ¬ with both Chinese and English words."
        ]
        
        for i, text in enumerate(test_cases, 1):
            print(f"\\n   æµ‹è¯• {i}: {text[:30]}...")
            result = analyzer.analyze(text)
            print(f"     - è¯æ•°: {result['word_count']}")
            print(f"     - è¯­è¨€: {result['language']}")
            print(f"     - æƒ…æ„Ÿ: {result['sentiment']}")
            if result['keywords']:
                print(f"     - å…³é”®è¯: {', '.join(result['keywords'][:3])}")
        
    except Exception as e:
        print(f"   âœ— æ–‡æœ¬åˆ†æå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("\\n2. æµ‹è¯•è¯­éŸ³è¯†åˆ«å¼•æ“æ£€æµ‹...")
    try:
        # æµ‹è¯•å„ç§è¯­éŸ³è¯†åˆ«å¼•æ“çš„å¯ç”¨æ€§
        engines = []
        
        try:
            from faster_whisper import WhisperModel
            engines.append("faster-whisper")
        except ImportError:
            pass
        
        try:
            import whisper
            engines.append("openai-whisper")
        except ImportError:
            pass
        
        try:
            import speech_recognition as sr
            engines.append("SpeechRecognition")
        except ImportError:
            pass
        
        if engines:
            print(f"   âœ“ å¯ç”¨çš„è¯­éŸ³è¯†åˆ«å¼•æ“: {', '.join(engines)}")
        else:
            print("   âš  æ²¡æœ‰å¯ç”¨çš„è¯­éŸ³è¯†åˆ«å¼•æ“")
            
    except Exception as e:
        print(f"   âœ— è¯­éŸ³è¯†åˆ«å¼•æ“æ£€æµ‹å¤±è´¥: {e}")
    
    print("\\n3. å¯åŠ¨äº¤äº’å¼æ–‡æœ¬åˆ†æ...")
    try:
        from nlp.analyzer_independent import IndependentTextAnalyzer
        analyzer = IndependentTextAnalyzer()
        
        print("\\n" + "="*50)
        print("äº¤äº’å¼æ–‡æœ¬åˆ†æå™¨")
        print("è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†æï¼Œè¾“å…¥ 'quit' é€€å‡º")
        print("="*50)
        
        while True:
            try:
                text = input("\\nè¯·è¾“å…¥æ–‡æœ¬> ").strip()
                
                if text.lower() in ['quit', 'q', 'exit', 'é€€å‡º']:
                    print("é€€å‡ºåˆ†æå™¨")
                    break
                
                if not text:
                    print("è¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬")
                    continue
                
                # åˆ†ææ–‡æœ¬
                result = analyzer.analyze(text)
                
                print(f"\\nğŸ“Š åˆ†æç»“æœ:")
                print(f"   å­—ç¬¦æ•°: {result['char_count']}")
                print(f"   è¯æ•°: {result['word_count']}")
                print(f"   è¯­è¨€: {result['language']}")
                print(f"   æƒ…æ„Ÿ: {result['sentiment']}")
                
                if result['keywords']:
                    print(f"   å…³é”®è¯: {', '.join(result['keywords'][:5])}")
                
                if result['word_frequency']:
                    print(f"   é«˜é¢‘è¯: {', '.join(list(result['word_frequency'].keys())[:3])}")
                
                # æ˜¾ç¤ºåˆ†è¯ç»“æœï¼ˆå‰10ä¸ªï¼‰
                if result['tokens']:
                    tokens_preview = result['tokens'][:10]
                    print(f"   åˆ†è¯é¢„è§ˆ: {' | '.join(tokens_preview)}")
                
            except KeyboardInterrupt:
                print("\\n\\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºåˆ†æå™¨")
                break
            except Exception as e:
                print(f"åˆ†æå‡ºé”™: {e}")
        
    except Exception as e:
        print(f"   âœ— äº¤äº’å¼åˆ†æå™¨å¯åŠ¨å¤±è´¥: {e}")
    
    print("\\n" + "="*60)
    print("ç³»ç»ŸåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("="*60)

if __name__ == "__main__":
    main()
